{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6933b98e-293e-4c4c-a6e6-493c66a4b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-24 11:25:49 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230224-112549.log\u001b[0m\n",
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[33mWARNING \u001b[0m 2023-02-24 11:25:50 - warn_once - `icecube` not available. Some functionality may be missing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.optim.adam import Adam\n",
    "from graphnet.data.constants import FEATURES, TRUTH\n",
    "from graphnet.models import StandardModel\n",
    "from graphnet.models.detector.icecube import IceCubeKaggle\n",
    "from graphnet.models.gnn import DynEdge\n",
    "from graphnet.models.graph_builders import KNNGraphBuilder\n",
    "from graphnet.models.task.reconstruction import DirectionReconstructionWithKappa, ZenithReconstructionWithKappa, AzimuthReconstructionWithKappa\n",
    "from graphnet.training.callbacks import ProgressBar, PiecewiseLinearLR\n",
    "from graphnet.training.loss_functions import VonMisesFisher3DLoss, VonMisesFisher2DLoss\n",
    "from graphnet.training.labels import Direction\n",
    "from graphnet.training.utils import make_dataloader\n",
    "from graphnet.utilities.logging import get_logger\n",
    "from pytorch_lightning import Trainer\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import numpy as np\n",
    "\n",
    "from graphnet.data.sqlite.sqlite_utilities import create_table\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "def build_model(config: Dict[str,Any], train_dataloader: Any) -> StandardModel:\n",
    "    \"\"\"Builds GNN from config\"\"\"\n",
    "    # Building model\n",
    "    detector = IceCubeKaggle(\n",
    "        graph_builder=KNNGraphBuilder(nb_nearest_neighbours=8),\n",
    "    )\n",
    "    gnn = DynEdge(\n",
    "        nb_inputs=detector.nb_outputs,\n",
    "        global_pooling_schemes=[\"min\", \"max\", \"mean\"],\n",
    "    )\n",
    "\n",
    "    if config[\"target\"] == 'direction':\n",
    "        task = DirectionReconstructionWithKappa(\n",
    "            hidden_size=gnn.nb_outputs,\n",
    "            target_labels=config[\"target\"],\n",
    "            loss_function=VonMisesFisher3DLoss(),\n",
    "        )\n",
    "        prediction_columns = [config[\"target\"] + \"_x\", \n",
    "                              config[\"target\"] + \"_y\", \n",
    "                              config[\"target\"] + \"_z\", \n",
    "                              config[\"target\"] + \"_kappa\" ]\n",
    "        additional_attributes = ['zenith', 'azimuth', 'event_id']\n",
    "\n",
    "    model = StandardModel(\n",
    "        detector=detector,\n",
    "        gnn=gnn,\n",
    "        tasks=[task],\n",
    "        optimizer_class=Adam,\n",
    "        optimizer_kwargs={\"lr\": 1e-03, \"eps\": 1e-03},\n",
    "        scheduler_class=PiecewiseLinearLR,\n",
    "        scheduler_kwargs={\n",
    "            \"milestones\": [\n",
    "                0,\n",
    "                len(train_dataloader) / 2,\n",
    "                len(train_dataloader) * config[\"fit\"][\"max_epochs\"],\n",
    "            ],\n",
    "            \"factors\": [1e-02, 1, 1e-02],\n",
    "        },\n",
    "        scheduler_config={\n",
    "            \"interval\": \"step\",\n",
    "        },\n",
    "    )\n",
    "    model.prediction_columns = prediction_columns\n",
    "    model.additional_attributes = additional_attributes\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_pretrained_model(config: Dict[str,Any], state_dict_path: str) -> StandardModel:\n",
    "    train_dataloader, _ = make_dataloaders(config = config)\n",
    "    model = build_model(config = config, \n",
    "                        train_dataloader = train_dataloader)\n",
    "    #model._inference_trainer = Trainer(config['fit'])\n",
    "    model.load_state_dict(state_dict_path)\n",
    "    model.prediction_columns = [config[\"target\"] + \"_x\", \n",
    "                              config[\"target\"] + \"_y\", \n",
    "                              config[\"target\"] + \"_z\", \n",
    "                              config[\"target\"] + \"_kappa\" ]\n",
    "    model.additional_attributes = ['event_id'] #'zenith', 'azimuth',  not available in test data\n",
    "    return model\n",
    "\n",
    "def make_dataloaders(config: Dict[str, Any]) -> List[Any]:\n",
    "    \"\"\"Constructs training and validation dataloaders for training with early stopping.\"\"\"\n",
    "    \n",
    "    train_dataloader = make_dataloader(db = config['path'],\n",
    "                                            selection = pd.read_csv(config['train_selection'])[config['index_column']].ravel().tolist() if config['train_selection'] else None,\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = True,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "    \n",
    "    validate_dataloader = make_dataloader(db = config['path'],\n",
    "                                            selection = pd.read_csv(config['validate_selection'])[config['index_column']].ravel().tolist() if config['validate_selection'] else None,\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = False,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                          \n",
    "                                            )\n",
    "    return train_dataloader, validate_dataloader\n",
    "\n",
    "def inference(model, config: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Applies model to the database specified in config['inference_database_path'] and saves results to disk.\"\"\"\n",
    "    # Make Dataloader\n",
    "    test_dataloader = make_dataloader(db = config['inference_database_path'],\n",
    "                                            selection = None, # Entire database\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = False,\n",
    "                                            labels = None, # Cannot make labels in test data\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "    \n",
    "    # Get predictions\n",
    "    results = model.predict_as_dataframe(\n",
    "        gpus = [0],\n",
    "        dataloader = test_dataloader,\n",
    "        prediction_columns=model.prediction_columns,\n",
    "        additional_attributes=['event_id']\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45576ee1-c905-4dda-ac63-397df36ec4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphnet.utilities.config import (\n",
    "    DatasetConfig,\n",
    "    ModelConfig,\n",
    "    TrainingConfig,\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from graphnet.training.callbacks import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767f23be-e725-48c7-9657-9d7b67ad1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_DIR = \"./wandb/\"\n",
    "os.makedirs(WANDB_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c562869-d2d7-4e4f-a9b2-000df7349aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/jupyter/experiments_logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c038c6-78f4-4a73-a8c7-42d25848fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "features = FEATURES.KAGGLE\n",
    "truth = TRUTH.KAGGLE\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "        \"path\" : '../data/train_database_52_53.db',\n",
    "        \"train_path\": '../data/train_database_52_53.db',\n",
    "        \"val_path\": '../data/train_database_54_55.db',\n",
    "        \"inference_database_path\": '../data/train_database_56_57.db',\n",
    "        \"pulsemap\": 'pulse_table',\n",
    "        \"truth_table\": 'meta_table',\n",
    "        \"features\": features,\n",
    "        \"truth\": truth,\n",
    "        \"index_column\": 'event_id',\n",
    "        \"run_name_tag\": 'graphnet_train_52_53',\n",
    "        \"batch_size\": 2,\n",
    "        \"num_workers\": 8,\n",
    "        \"target\": 'direction',\n",
    "        \"early_stopping_patience\": 5,\n",
    "        \"fit\": {\n",
    "                \"max_epochs\": 1,\n",
    "                \"gpus\": [0],\n",
    "                \"distribution_strategy\": None,\n",
    "                },\n",
    "        'train_selection': None,\n",
    "        'validate_selection':  None,\n",
    "        'test_selection': None,\n",
    "        'base_dir': '../training_52_53'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0283731d-3d38-4ae3-a915-125e071864d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config : Dict[str,Any], \n",
    "          state_dict_path : str, db_name : str, run_name : str):\n",
    "    model = load_pretrained_model(config = config, state_dict_path=state_dict_path)\n",
    "    \n",
    "    train_dataloader = make_dataloader(db = config['train_path'],\n",
    "                                            selection = pd.read_csv(config['train_selection'])[config['index_column']].ravel().tolist() if config['train_selection'] else None,\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = True,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "    val_dataloader = make_dataloader(db = config['val_path'],\n",
    "                                            selection = pd.read_csv(config['validate_selection'])[config['index_column']].ravel().tolist() if config['validate_selection'] else None,\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = True,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "\n",
    "    test_dataloader = make_dataloader(db = config['inference_database_path'],\n",
    "                                            selection = None, # Entire database\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = False,\n",
    "                                            labels = None, # Cannot make labels in test data\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "    \n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"kaggle-ice-cube\",\n",
    "        entity=\"ikarus5991\",\n",
    "        save_dir=WANDB_DIR,\n",
    "        log_model=True,\n",
    "    )\n",
    "    config = TrainingConfig(\n",
    "        target=[\n",
    "            target for task in model._tasks for target in task._target_labels\n",
    "        ],\n",
    "        early_stopping_patience=config[\"early_stopping_patience\"],\n",
    "        fit=config[\"fit\"],\n",
    "        dataloader={\"batch_size\": config[\"batch_size\"], \"num_workers\": config[\"num_workers\"]},\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=config.early_stopping_patience,\n",
    "        ),\n",
    "        ProgressBar(),\n",
    "    ]\n",
    "    \n",
    "    model.fit(\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        callbacks=callbacks,\n",
    "        logger=wandb_logger,\n",
    "        **config.fit,\n",
    "    )\n",
    "    \n",
    "    path = os.path.join(OUTPUT_DIR, db_name, run_name)\n",
    "    logger.info(f\"Writing results to {path}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    model.save_state_dict(f\"{path}/state_dict.pth\")\n",
    "    model.save(f\"{path}/model.pth\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48cb03c-563a-4cf3-ab4b-abfebc123a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mikarus5991\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/wandb/run-20230224_112556-11ws4x8x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ikarus5991/kaggle-ice-cube/runs/11ws4x8x\" target=\"_blank\">vivid-cosmos-16</a></strong> to <a href=\"https://wandb.ai/ikarus5991/kaggle-ice-cube\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb25342d6bc497bbc6ba91e758cf4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(config, \"../dynedge_pretrained_batch_1_to_50/state_dict.pth\", 'batch_[52-53]', 'general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f46aa3-7c6b-48ac-8fd7-444aa3939cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
